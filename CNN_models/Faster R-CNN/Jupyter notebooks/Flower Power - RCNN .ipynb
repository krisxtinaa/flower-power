{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89df6e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util\n",
    "import cv2\n",
    "import numpy as np\n",
    "#from matplotlib import pyplot as plt\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Qt5Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f614d454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x22d939da190>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs = config_util.get_configs_from_pipeline_file(\n",
    "    r\"C:\\Users\\Philip Vangelov\\PycharmProjects\\pythonProject\\TensorFlow\\workspace\\training_demo\\models\\faster_rcnn_resnet_v2_update_2\\pipeline.config\")\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(\n",
    "    r\"C:\\Users\\Philip Vangelov\\PycharmProjects\\pythonProject\\TensorFlow\\workspace\\training_demo\\models\\faster_rcnn_resnet_v2_update_2\\ckpt-16\").expect_partial()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "279a201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02508aa8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 35,  59,  51],\n",
       "        [ 29,  53,  45],\n",
       "        [ 31,  58,  49],\n",
       "        ...,\n",
       "        [ 27,  52,  42],\n",
       "        [ 22,  48,  35],\n",
       "        [ 35,  61,  48]],\n",
       "\n",
       "       [[ 42,  65,  57],\n",
       "        [ 33,  57,  49],\n",
       "        [ 31,  55,  47],\n",
       "        ...,\n",
       "        [ 18,  43,  33],\n",
       "        [ 38,  64,  51],\n",
       "        [ 35,  63,  50]],\n",
       "\n",
       "       [[ 43,  64,  56],\n",
       "        [ 36,  59,  51],\n",
       "        [ 30,  53,  45],\n",
       "        ...,\n",
       "        [ 30,  57,  47],\n",
       "        [ 33,  61,  48],\n",
       "        [ 50,  80,  67]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 78, 108,  89],\n",
       "        [ 63,  91,  72],\n",
       "        [ 39,  60,  45],\n",
       "        ...,\n",
       "        [128, 118, 111],\n",
       "        [130, 121, 112],\n",
       "        [124, 115, 106]],\n",
       "\n",
       "       [[ 59,  90,  69],\n",
       "        [ 67,  95,  76],\n",
       "        [ 57,  78,  63],\n",
       "        ...,\n",
       "        [129, 119, 112],\n",
       "        [127, 118, 109],\n",
       "        [133, 124, 115]],\n",
       "\n",
       "       [[ 58,  89,  68],\n",
       "        [ 53,  81,  61],\n",
       "        [ 43,  64,  49],\n",
       "        ...,\n",
       "        [135, 125, 118],\n",
       "        [128, 119, 110],\n",
       "        [141, 132, 123]]], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(\n",
    "    r\"C:\\Users\\Philip Vangelov\\PycharmProjects\\pythonProject\\TensorFlow\\workspace\\annotations\\label_map.pbtxt\")\n",
    "\n",
    "IMAGE_PATH = r\"C:\\Users\\Philip Vangelov\\PycharmProjects\\pythonProject\\TensorFlow\\workspace\\training_demo\\images\\images_4\\test\\Brown Knapweed_B4A7881.jpg\"\n",
    "\n",
    "img = cv2.imread(IMAGE_PATH)\n",
    "image_np = np.array(img)\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "detections = detect_fn(input_tensor)\n",
    "\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy()\n",
    "              for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "\n",
    "# detection_classes should be ints.\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "label_id_offset = 1\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "    image_np_with_detections,\n",
    "    detections['detection_boxes'],\n",
    "    detections['detection_classes'] + label_id_offset,\n",
    "    detections['detection_scores'],\n",
    "    category_index,\n",
    "    use_normalized_coordinates=True,\n",
    "    max_boxes_to_draw=150,\n",
    "    min_score_thresh=0.01,\n",
    "    agnostic_mode=False,skip_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca6a0204",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b5a0146",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_score = 0.1 # Chose min score for the detections\n",
    "chosen_detections = []\n",
    "for index,value in enumerate(zip(detections['detection_scores'],detections['detection_classes'])):\n",
    "    if value[0] > min_score:\n",
    "        chosen_detections.append(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d4a4d59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.9925029, 3), (0.9853914, 3), (0.97365665, 3), (0.9394185, 3), (0.9120266, 3), (0.8940744, 3), (0.8849586, 3), (0.83260113, 3), (0.82629913, 3), (0.8158715, 3), (0.79566854, 3), (0.7234796, 3), (0.70686424, 3), (0.69063663, 3), (0.68297297, 3), (0.6685154, 3), (0.6483147, 3), (0.5977895, 3), (0.5820531, 3), (0.518069, 3), (0.5051655, 3), (0.32462487, 3), (0.29748, 3), (0.23062256, 3), (0.20569548, 1), (0.17436408, 3), (0.17033729, 3), (0.14830528, 3)]\n"
     ]
    }
   ],
   "source": [
    "print(chosen_detections)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
